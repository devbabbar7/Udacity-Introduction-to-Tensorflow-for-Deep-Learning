{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devbabbar7/Udacity-Introduction-to-Tensorflow-for-Deep-Learning/blob/main/l10c04_nlp_optimizing_the_text_generation_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph5eir3Pf-3z"
      },
      "source": [
        "# Optimizing the Text Generation Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCxhW3mtLmfb"
      },
      "source": [
        "You've already done some amazing work with generating new songs, but so far we've seen some issues with repetition and a fair amount of incoherence. By using more data and further tweaking the model, you'll be able to get improved results. We'll once again use the [Kaggle Song Lyrics Dataset](https://www.kaggle.com/mousehead/songlyrics) here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aHK2CYygXom"
      },
      "source": [
        "## Import TensorFlow and related functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2LmLTREBf5ng"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Other imports for processing data\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmLTO_dpgge9"
      },
      "source": [
        "## Get the Dataset\n",
        "\n",
        "As noted above, we'll utilize the [Song Lyrics dataset](https://www.kaggle.com/mousehead/songlyrics) on Kaggle again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4Bf5FVHfganK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ff8c5f9-9e62-4f6d-99e4-46264dcaf5fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-04 19:55:19--  https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.135.100, 74.125.135.139, 74.125.135.138, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.135.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/n3dbrpkuhs78e45smvp7itguu71gb5kv/1685908500000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8?uuid=29dc6e80-29fd-41e7-8058-75e92cf1160c [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-06-04 19:55:21--  https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/n3dbrpkuhs78e45smvp7itguu71gb5kv/1685908500000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8?uuid=29dc6e80-29fd-41e7-8058-75e92cf1160c\n",
            "Resolving doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)... 108.177.98.132, 2607:f8b0:400e:c06::84\n",
            "Connecting to doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)|108.177.98.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 72436445 (69M) [text/csv]\n",
            "Saving to: ‘/tmp/songdata.csv’\n",
            "\n",
            "/tmp/songdata.csv   100%[===================>]  69.08M   190MB/s    in 0.4s    \n",
            "\n",
            "2023-06-04 19:55:22 (190 MB/s) - ‘/tmp/songdata.csv’ saved [72436445/72436445]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 \\\n",
        "    -O /tmp/songdata.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz9x-7dWihxx"
      },
      "source": [
        "## 250 Songs\n",
        "\n",
        "Now we've seen a model trained on just a small sample of songs, and how this often leads to repetition as you get further along in trying to generate new text. Let's switch to using the 250 songs instead, and see if our output improves. This will actually be nearly 10K lines of lyrics, which should be sufficient.\n",
        "\n",
        "Note that we won't use the full dataset here as it will take up quite a bit of RAM and processing time, but you're welcome to try doing so on your own later. If interested, you'll likely want to use only some of the more common words for the Tokenizer, which will help shrink processing time and memory needed (or else you'd have an output array hundreds of thousands of words long)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWbMN_19jfRT"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LRmPPJegovBe"
      },
      "outputs": [],
      "source": [
        "def tokenize_corpus(corpus, num_words=-1):\n",
        "  # Fit a Tokenizer on the corpus\n",
        "  if num_words > -1:\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "  else:\n",
        "    tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  return tokenizer\n",
        "\n",
        "def create_lyrics_corpus(dataset, field):\n",
        "  # Remove all other punctuation\n",
        "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
        "  # Make it lowercase\n",
        "  dataset[field] = dataset[field].str.lower()\n",
        "  # Make it one long string to split by line\n",
        "  lyrics = dataset[field].str.cat()\n",
        "  corpus = lyrics.split('\\n')\n",
        "  # Remove any trailing whitespace\n",
        "  for l in range(len(corpus)):\n",
        "    corpus[l] = corpus[l].rstrip()\n",
        "  # Remove any empty lines\n",
        "  corpus = [l for l in corpus if l != '']\n",
        "\n",
        "  return corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kIGedF3XjHj4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d50f659-7a2b-486c-d52f-c6d41604fab5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-fbdddccf8583>:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000\n"
          ]
        }
      ],
      "source": [
        "def tokenize_corpus(corpus, num_words=-1):\n",
        "  # Fit a Tokenizer on the corpus\n",
        "  if num_words > -1:\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "  else:\n",
        "    tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  return tokenizer\n",
        "\n",
        "# Read the dataset from csv - this time with 250 songs\n",
        "dataset = pd.read_csv('/tmp/songdata.csv', dtype=str)[:250]\n",
        "# Create the corpus using the 'text' column containing lyrics\n",
        "corpus = create_lyrics_corpus(dataset, 'text')\n",
        "# Tokenize the corpus\n",
        "tokenizer = tokenize_corpus(corpus, num_words=2000)\n",
        "total_words = tokenizer.num_words\n",
        "\n",
        "# There should be a lot more words now\n",
        "print(total_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quoDmw_FkNBA"
      },
      "source": [
        "### Create Sequences and Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kkLAf3HmkPSo"
      },
      "outputs": [],
      "source": [
        "sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tsequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences for equal input length \n",
        "max_sequence_len = max([len(seq) for seq in sequences])\n",
        "sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# Split sequences between the \"input\" sequence and \"output\" predicted word\n",
        "input_sequences, labels = sequences[:,:-1], sequences[:,-1]\n",
        "# One-hot encode the labels\n",
        "one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cECbqT-blMk-"
      },
      "source": [
        "### Train a (Better) Text Generation Model\n",
        "\n",
        "With more data, we'll cut off after 100 epochs to avoid keeping you here all day. You'll also want to change your runtime type to GPU if you haven't already (you'll need to re-run the above cells if you change runtimes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7nHOp6uWlP_P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "960ae6a7-c795-4487-c915-a8d9ea6d6cd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1480/1480 [==============================] - 33s 15ms/step - loss: 5.9795 - accuracy: 0.0469\n",
            "Epoch 2/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 5.6879 - accuracy: 0.0514\n",
            "Epoch 3/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 5.4760 - accuracy: 0.0728\n",
            "Epoch 4/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 5.2865 - accuracy: 0.1032\n",
            "Epoch 5/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 5.1486 - accuracy: 0.1141\n",
            "Epoch 6/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 5.0281 - accuracy: 0.1248\n",
            "Epoch 7/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 4.9072 - accuracy: 0.1378\n",
            "Epoch 8/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 4.7730 - accuracy: 0.1492\n",
            "Epoch 9/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 4.6330 - accuracy: 0.1647\n",
            "Epoch 10/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 4.5017 - accuracy: 0.1801\n",
            "Epoch 11/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 4.3888 - accuracy: 0.1928\n",
            "Epoch 12/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 4.2909 - accuracy: 0.2026\n",
            "Epoch 13/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 4.2038 - accuracy: 0.2148\n",
            "Epoch 14/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 4.1270 - accuracy: 0.2240\n",
            "Epoch 15/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 4.0550 - accuracy: 0.2335\n",
            "Epoch 16/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.9905 - accuracy: 0.2417\n",
            "Epoch 17/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.9295 - accuracy: 0.2516\n",
            "Epoch 18/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.8768 - accuracy: 0.2580\n",
            "Epoch 19/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.8223 - accuracy: 0.2664\n",
            "Epoch 20/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.7732 - accuracy: 0.2714\n",
            "Epoch 21/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.7265 - accuracy: 0.2757\n",
            "Epoch 22/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.6868 - accuracy: 0.2823\n",
            "Epoch 23/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.6405 - accuracy: 0.2876\n",
            "Epoch 24/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.5996 - accuracy: 0.2946\n",
            "Epoch 25/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.5586 - accuracy: 0.3018\n",
            "Epoch 26/100\n",
            "1480/1480 [==============================] - 10s 7ms/step - loss: 3.5198 - accuracy: 0.3062\n",
            "Epoch 27/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.4851 - accuracy: 0.3124\n",
            "Epoch 28/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.4522 - accuracy: 0.3148\n",
            "Epoch 29/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.4202 - accuracy: 0.3200\n",
            "Epoch 30/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.3894 - accuracy: 0.3264\n",
            "Epoch 31/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.3538 - accuracy: 0.3300\n",
            "Epoch 32/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.3279 - accuracy: 0.3328\n",
            "Epoch 33/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.2962 - accuracy: 0.3376\n",
            "Epoch 34/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.2680 - accuracy: 0.3438\n",
            "Epoch 35/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.2426 - accuracy: 0.3468\n",
            "Epoch 36/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.2128 - accuracy: 0.3510\n",
            "Epoch 37/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.1932 - accuracy: 0.3527\n",
            "Epoch 38/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.1687 - accuracy: 0.3559\n",
            "Epoch 39/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.1483 - accuracy: 0.3593\n",
            "Epoch 40/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.1216 - accuracy: 0.3641\n",
            "Epoch 41/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.0991 - accuracy: 0.3668\n",
            "Epoch 42/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.0760 - accuracy: 0.3705\n",
            "Epoch 43/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.0615 - accuracy: 0.3737\n",
            "Epoch 44/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.0363 - accuracy: 0.3779\n",
            "Epoch 45/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.0144 - accuracy: 0.3820\n",
            "Epoch 46/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.9932 - accuracy: 0.3840\n",
            "Epoch 47/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.9820 - accuracy: 0.3866\n",
            "Epoch 48/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.9611 - accuracy: 0.3902\n",
            "Epoch 49/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.9464 - accuracy: 0.3932\n",
            "Epoch 50/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.9237 - accuracy: 0.3953\n",
            "Epoch 51/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.9056 - accuracy: 0.3997\n",
            "Epoch 52/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.8920 - accuracy: 0.4017\n",
            "Epoch 53/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.8738 - accuracy: 0.4053\n",
            "Epoch 54/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.8622 - accuracy: 0.4079\n",
            "Epoch 55/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.8386 - accuracy: 0.4105\n",
            "Epoch 56/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.8247 - accuracy: 0.4113\n",
            "Epoch 57/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.8071 - accuracy: 0.4174\n",
            "Epoch 58/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.8004 - accuracy: 0.4163\n",
            "Epoch 59/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.7784 - accuracy: 0.4214\n",
            "Epoch 60/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.7711 - accuracy: 0.4235\n",
            "Epoch 61/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.7512 - accuracy: 0.4248\n",
            "Epoch 62/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.7414 - accuracy: 0.4262\n",
            "Epoch 63/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.7377 - accuracy: 0.4275\n",
            "Epoch 64/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.7162 - accuracy: 0.4311\n",
            "Epoch 65/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.7018 - accuracy: 0.4321\n",
            "Epoch 66/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.6895 - accuracy: 0.4347\n",
            "Epoch 67/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.6753 - accuracy: 0.4371\n",
            "Epoch 68/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.6616 - accuracy: 0.4420\n",
            "Epoch 69/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.6492 - accuracy: 0.4426\n",
            "Epoch 70/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.6486 - accuracy: 0.4421\n",
            "Epoch 71/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.6340 - accuracy: 0.4460\n",
            "Epoch 72/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.6263 - accuracy: 0.4475\n",
            "Epoch 73/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.6093 - accuracy: 0.4504\n",
            "Epoch 74/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.5953 - accuracy: 0.4517\n",
            "Epoch 75/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.5872 - accuracy: 0.4543\n",
            "Epoch 76/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.5716 - accuracy: 0.4578\n",
            "Epoch 77/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.5639 - accuracy: 0.4578\n",
            "Epoch 78/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.5576 - accuracy: 0.4588\n",
            "Epoch 79/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.5418 - accuracy: 0.4613\n",
            "Epoch 80/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.5503 - accuracy: 0.4596\n",
            "Epoch 81/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.5275 - accuracy: 0.4660\n",
            "Epoch 82/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.5115 - accuracy: 0.4682\n",
            "Epoch 83/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.5150 - accuracy: 0.4673\n",
            "Epoch 84/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.4955 - accuracy: 0.4705\n",
            "Epoch 85/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.4862 - accuracy: 0.4707\n",
            "Epoch 86/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.4773 - accuracy: 0.4726\n",
            "Epoch 87/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.4707 - accuracy: 0.4752\n",
            "Epoch 88/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.4576 - accuracy: 0.4775\n",
            "Epoch 89/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.4528 - accuracy: 0.4770\n",
            "Epoch 90/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.4475 - accuracy: 0.4792\n",
            "Epoch 91/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.4442 - accuracy: 0.4784\n",
            "Epoch 92/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.4232 - accuracy: 0.4826\n",
            "Epoch 93/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.4200 - accuracy: 0.4852\n",
            "Epoch 94/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.4171 - accuracy: 0.4831\n",
            "Epoch 95/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.4005 - accuracy: 0.4886\n",
            "Epoch 96/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.3948 - accuracy: 0.4878\n",
            "Epoch 97/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.3995 - accuracy: 0.4874\n",
            "Epoch 98/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.3873 - accuracy: 0.4904\n",
            "Epoch 99/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.3798 - accuracy: 0.4916\n",
            "Epoch 100/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.3682 - accuracy: 0.4934\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(20)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(input_sequences, one_hot_labels, epochs=100, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgvIz20nlQcq"
      },
      "source": [
        "### View the Training Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rOqmmarvlSLh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "8d82d1ae-d4f1-450e-c7a4-c57e5024e2fc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()\n",
        "\n",
        "plot_graphs(history, 'accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISLZZGlQlSxh"
      },
      "source": [
        "### Generate better lyrics!\n",
        "\n",
        "This time around, we should be able to get a more interesting output with less repetition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "P96oVMk3lU7y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbf52a5b-4184-4cc3-a016-5964df2122db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 646ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "im feeling chills babe and your sunny side kong song twice love can farm hey hey hey hey world turn fairy nosotros kin solitude holler holler holler holler kiss kiss kiss kiss kiss lala holler holler kiss lala holler kiss harm fairy opened mans block chance to smells luck it up it yeah with you too fast and you cant fever fever fever fever fever fever meant for wearing sin you house mans midnight mans fever whom soul sin nancy shit outta luck from to die but i get it up get it up cmon nancy get to play emotions away of me\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upgJKV8_oRU9"
      },
      "source": [
        "### Varying the Possible Outputs\n",
        "\n",
        "In running the above, you may notice that the same seed text will generate similar outputs. This is because the code is currently always choosing the top predicted class as the next word. What if you wanted more variance in the output? \n",
        "\n",
        "Switching from `model.predict_classes` to `model.predict_proba` will get us all of the class probabilities. We can combine this with `np.random.choice` to select a given predicted output based on a probability, thereby giving a bit more randomness to our outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lZe9gaJeoGVP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7989f91-94b9-4a9e-e88b-7fb42df5793d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "143\n"
          ]
        }
      ],
      "source": [
        "# Test the method with just the first word after the seed text\n",
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "predicted_probs = model.predict(token_list)[0]\n",
        "predicted = np.random.choice([x for x in range(len(predicted_probs))], \n",
        "                             p=predicted_probs)\n",
        "# Running this cell multiple times should get you some variance in output\n",
        "print(predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ee7WKgRGrJy1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45ea7e63-813d-4329-8223-daf99df3e234"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "im feeling chills ill hold a reason for i heart rockn hits he love song wanna find chat hammer wanna minute city you say give me more the lonely pages on upon kiss kiss kiss lala set kiss harm harm harm kiss kiss kiss hurt harm use kiss harm kiss kiss harm harm kiss kiss harm harm kiss kiss kiss harm pan kiss creature treasure harm kiss harm kiss harm kiss use choose capture harm use blame kiss kiss kiss kiss woogie suzyhangaround laughed kiss kiss harm kiss sword set remember go kiss harm kiss kiss use foolish write harm pan wing spread\n"
          ]
        }
      ],
      "source": [
        "# Use this process for the full output generation\n",
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "  token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "  token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "  predicted_probs = model.predict(token_list)[0]\n",
        "  predicted = np.random.choice([x for x in range(len(predicted_probs))],\n",
        "                               p=predicted_probs)\n",
        "  output_word = \"\"\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == predicted:\n",
        "      output_word = word\n",
        "      break\n",
        "  seed_text += \" \" + output_word\n",
        "print(seed_text)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}