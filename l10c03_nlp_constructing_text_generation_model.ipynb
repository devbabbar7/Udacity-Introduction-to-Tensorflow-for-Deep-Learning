{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devbabbar7/Udacity-Introduction-to-Tensorflow-for-Deep-Learning/blob/main/l10c03_nlp_constructing_text_generation_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph5eir3Pf-3z"
      },
      "source": [
        "# Constructing a Text Generation Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GbGfr_oLCat"
      },
      "source": [
        "Using most of the techniques you've already learned, it's now possible to generate new text by predicting the next word that follows a given seed word. To practice this method, we'll use the [Kaggle Song Lyrics Dataset](https://www.kaggle.com/mousehead/songlyrics)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aHK2CYygXom"
      },
      "source": [
        "## Import TensorFlow and related functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2LmLTREBf5ng"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Other imports for processing data\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmLTO_dpgge9"
      },
      "source": [
        "## Get the Dataset\n",
        "\n",
        "As noted above, we'll utilize the [Song Lyrics dataset](https://www.kaggle.com/mousehead/songlyrics) on Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4Bf5FVHfganK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeb99b60-19f1-4879-ac27-2c06745bf70a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-04 19:52:03--  https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
            "Resolving drive.google.com (drive.google.com)... 142.250.4.139, 142.250.4.101, 142.250.4.138, ...\n",
            "Connecting to drive.google.com (drive.google.com)|142.250.4.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/fr7iu7aah6tl3fbjeudk3i29ptnb6ivj/1685908275000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8?uuid=fd665fae-2812-4221-aba9-b8033224e81d [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-06-04 19:52:05--  https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/fr7iu7aah6tl3fbjeudk3i29ptnb6ivj/1685908275000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8?uuid=fd665fae-2812-4221-aba9-b8033224e81d\n",
            "Resolving doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)... 74.125.200.132, 2404:6800:4003:c00::84\n",
            "Connecting to doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)|74.125.200.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 72436445 (69M) [text/csv]\n",
            "Saving to: ‘/tmp/songdata.csv’\n",
            "\n",
            "/tmp/songdata.csv   100%[===================>]  69.08M  68.2MB/s    in 1.0s    \n",
            "\n",
            "2023-06-04 19:52:07 (68.2 MB/s) - ‘/tmp/songdata.csv’ saved [72436445/72436445]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 \\\n",
        "    -O /tmp/songdata.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gu1BTzMIS1oy"
      },
      "source": [
        "## **First 10 Songs**\n",
        "\n",
        "Let's first look at just 10 songs from the dataset, and see how things perform."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmb9rGaAUDO-"
      },
      "source": [
        "### Preprocessing\n",
        "\n",
        "Let's perform some basic preprocessing to get rid of punctuation and make everything lowercase. We'll then split the lyrics up by line and tokenize the lyrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2AVAvyF_Vuh5"
      },
      "outputs": [],
      "source": [
        "def tokenize_corpus(corpus, num_words=-1):\n",
        "  # Fit a Tokenizer on the corpus\n",
        "  if num_words > -1:\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "  else:\n",
        "    tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  return tokenizer\n",
        "\n",
        "def create_lyrics_corpus(dataset, field):\n",
        "  # Remove all other punctuation\n",
        "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
        "  # Make it lowercase\n",
        "  dataset[field] = dataset[field].str.lower()\n",
        "  # Make it one long string to split by line\n",
        "  lyrics = dataset[field].str.cat()\n",
        "  corpus = lyrics.split('\\n')\n",
        "  # Remove any trailing whitespace\n",
        "  for l in range(len(corpus)):\n",
        "    corpus[l] = corpus[l].rstrip()\n",
        "  # Remove any empty lines\n",
        "  corpus = [l for l in corpus if l != '']\n",
        "\n",
        "  return corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "apcEXp7WhVBs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "191c3834-e10f-43cc-add5-9189ae1afe58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'you': 1, 'i': 2, 'and': 3, 'a': 4, 'me': 5, 'the': 6, 'is': 7, 'my': 8, 'to': 9, 'ma': 10, 'it': 11, 'of': 12, 'im': 13, 'your': 14, 'love': 15, 'so': 16, 'as': 17, 'that': 18, 'in': 19, 'andante': 20, 'boomaboomerang': 21, 'make': 22, 'on': 23, 'oh': 24, 'for': 25, 'but': 26, 'new': 27, 'bang': 28, 'its': 29, 'be': 30, 'like': 31, 'know': 32, 'now': 33, 'how': 34, 'could': 35, 'youre': 36, 'sing': 37, 'never': 38, 'no': 39, 'chiquitita': 40, 'can': 41, 'we': 42, 'song': 43, 'had': 44, 'good': 45, 'youll': 46, 'she': 47, 'just': 48, 'girl': 49, 'again': 50, 'will': 51, 'take': 52, 'please': 53, 'let': 54, 'am': 55, 'eyes': 56, 'was': 57, 'always': 58, 'cassandra': 59, 'blue': 60, 'time': 61, 'dont': 62, 'were': 63, 'return': 64, 'once': 65, 'then': 66, 'sorry': 67, 'cryin': 68, 'over': 69, 'feel': 70, 'ever': 71, 'believe': 72, 'what': 73, 'do': 74, 'go': 75, 'all': 76, 'out': 77, 'think': 78, 'every': 79, 'leave': 80, 'look': 81, 'at': 82, 'way': 83, 'one': 84, 'music': 85, 'down': 86, 'our': 87, 'give': 88, 'learn': 89, 'more': 90, 'us': 91, 'would': 92, 'there': 93, 'before': 94, 'when': 95, 'with': 96, 'feeling': 97, 'play': 98, 'cause': 99, 'away': 100, 'here': 101, 'have': 102, 'yes': 103, 'baby': 104, 'get': 105, 'didnt': 106, 'see': 107, 'did': 108, 'closed': 109, 'realized': 110, 'crazy': 111, 'world': 112, 'lord': 113, 'shes': 114, 'kind': 115, 'without': 116, 'if': 117, 'touch': 118, 'strong': 119, 'making': 120, 'such': 121, 'found': 122, 'true': 123, 'stay': 124, 'together': 125, 'thought': 126, 'come': 127, 'they': 128, 'sweet': 129, 'tender': 130, 'sender': 131, 'tune': 132, 'humdehumhum': 133, 'gonna': 134, 'last': 135, 'leaving': 136, 'sleep': 137, 'only': 138, 'saw': 139, 'tell': 140, 'hes': 141, 'her': 142, 'sound': 143, 'tread': 144, 'lightly': 145, 'ground': 146, 'ill': 147, 'show': 148, 'life': 149, 'too': 150, 'used': 151, 'darling': 152, 'meant': 153, 'break': 154, 'end': 155, 'yourself': 156, 'little': 157, 'dumbedumdum': 158, 'bedumbedumdum': 159, 'youve': 160, 'dumbbedumbdumb': 161, 'bedumbbedumbdumb': 162, 'by': 163, 'theyre': 164, 'alone': 165, 'misunderstood': 166, 'day': 167, 'dawning': 168, 'some': 169, 'wanted': 170, 'none': 171, 'listen': 172, 'words': 173, 'warning': 174, 'darkest': 175, 'nights': 176, 'nobody': 177, 'knew': 178, 'fight': 179, 'caught': 180, 'really': 181, 'power': 182, 'dreams': 183, 'weave': 184, 'until': 185, 'final': 186, 'hour': 187, 'morning': 188, 'ship': 189, 'gone': 190, 'grieving': 191, 'still': 192, 'pain': 193, 'cry': 194, 'sun': 195, 'try': 196, 'face': 197, 'something': 198, 'sees': 199, 'makes': 200, 'fine': 201, 'who': 202, 'mine': 203, 'leaves': 204, 'walk': 205, 'hand': 206, 'well': 207, 'about': 208, 'things': 209, 'slow': 210, 'theres': 211, 'talk': 212, 'why': 213, 'up': 214, 'lousy': 215, 'packing': 216, 'ive': 217, 'gotta': 218, 'near': 219, 'keeping': 220, 'intention': 221, 'growing': 222, 'taking': 223, 'dimension': 224, 'even': 225, 'better': 226, 'thank': 227, 'god': 228, 'not': 229, 'somebody': 230, 'happy': 231, 'question': 232, 'smile': 233, 'mean': 234, 'much': 235, 'kisses': 236, 'around': 237, 'anywhere': 238, 'advice': 239, 'care': 240, 'use': 241, 'selfish': 242, 'tool': 243, 'fool': 244, 'showing': 245, 'boomerang': 246, 'throwing': 247, 'warm': 248, 'kiss': 249, 'surrender': 250, 'giving': 251, 'been': 252, 'door': 253, 'burning': 254, 'bridges': 255, 'being': 256, 'moving': 257, 'though': 258, 'behind': 259, 'are': 260, 'must': 261, 'sure': 262, 'stood': 263, 'hope': 264, 'this': 265, 'deny': 266, 'sad': 267, 'quiet': 268, 'truth': 269, 'heartaches': 270, 'scars': 271, 'dancing': 272, 'sky': 273, 'shining': 274, 'above': 275, 'hear': 276, 'came': 277, 'couldnt': 278, 'everything': 279, 'back': 280, 'long': 281, 'waitin': 282, 'cold': 283, 'chills': 284, 'bone': 285, 'youd': 286, 'wonderful': 287, 'means': 288, 'special': 289, 'smiles': 290, 'lucky': 291, 'fellow': 292, 'park': 293, 'holds': 294, 'squeezes': 295, 'walking': 296, 'hours': 297, 'talking': 298, 'plan': 299, 'easy': 300, 'gently': 301, 'summer': 302, 'evening': 303, 'breeze': 304, 'grow': 305, 'fingers': 306, 'soft': 307, 'light': 308, 'body': 309, 'velvet': 310, 'night': 311, 'soul': 312, 'slowly': 313, 'shimmer': 314, 'thousand': 315, 'butterflies': 316, 'float': 317, 'put': 318, 'rotten': 319, 'boy': 320, 'tough': 321, 'stuff': 322, 'saying': 323, 'need': 324, 'anymore': 325, 'enough': 326, 'standing': 327, 'creep': 328, 'felt': 329, 'cheap': 330, 'notion': 331, 'deep': 332, 'dumb': 333, 'mistake': 334, 'entitled': 335, 'another': 336, 'beg': 337, 'forgive': 338, 'an': 339, 'feels': 340, 'hoot': 341, 'holler': 342, 'mad': 343, 'under': 344, 'heel': 345, 'holy': 346, 'christ': 347, 'deal': 348, 'sick': 349, 'tired': 350, 'tedious': 351, 'ways': 352, 'aint': 353, 'walkin': 354, 'cutting': 355, 'tie': 356, 'wanna': 357, 'into': 358, 'eye': 359, 'myself': 360, 'counting': 361, 'pride': 362, 'unright': 363, 'neighbours': 364, 'ride': 365, 'burying': 366, 'past': 367, 'peace': 368, 'free': 369, 'sucker': 370, 'street': 371, 'singing': 372, 'shouting': 373, 'staying': 374, 'alive': 375, 'city': 376, 'dead': 377, 'hiding': 378, 'their': 379, 'shame': 380, 'hollow': 381, 'laughter': 382, 'while': 383, 'crying': 384, 'bed': 385, 'pity': 386, 'believed': 387, 'lost': 388, 'from': 389, 'start': 390, 'suffer': 391, 'sell': 392, 'secrets': 393, 'bargain': 394, 'playing': 395, 'smart': 396, 'aching': 397, 'hearts': 398, 'sailing': 399, 'father': 400, 'sister': 401, 'reason': 402, 'linger': 403, 'deeply': 404, 'future': 405, 'casting': 406, 'shadow': 407, 'else': 408, 'fate': 409, 'bags': 410, 'thorough': 411, 'knowing': 412, 'late': 413, 'wait': 414, 'watched': 415, 'harbor': 416, 'sunrise': 417, 'sails': 418, 'almost': 419, 'slack': 420, 'cool': 421, 'rain': 422, 'deck': 423, 'tiny': 424, 'figure': 425, 'rigid': 426, 'restrained': 427, 'filled': 428, 'whats': 429, 'wrong': 430, 'enchained': 431, 'own': 432, 'sorrow': 433, 'tomorrow': 434, 'hate': 435, 'shoulder': 436, 'best': 437, 'friend': 438, 'rely': 439, 'broken': 440, 'feather': 441, 'patch': 442, 'walls': 443, 'tumbling': 444, 'loves': 445, 'blown': 446, 'candle': 447, 'seems': 448, 'hard': 449, 'handle': 450, 'id': 451, 'thinking': 452, 'went': 453, 'house': 454, 'hardly': 455, 'guy': 456, 'closing': 457, 'front': 458, 'emptiness': 459, 'he': 460, 'disapeared': 461, 'his': 462, 'car': 463, 'stunned': 464, 'dreamed': 465, 'lifes': 466, 'part': 467, 'move': 468, 'feet': 469, 'pavement': 470, 'acted': 471, 'told': 472, 'lies': 473, 'meet': 474, 'other': 475, 'guys': 476, 'stupid': 477, 'blind': 478, 'smiled': 479, 'took': 480, 'said': 481, 'may': 482, 'couple': 483, 'men': 484, 'them': 485, 'brother': 486, 'joe': 487, 'seeing': 488, 'lot': 489, 'him': 490, 'nice': 491, 'sitting': 492, 'sittin': 493, 'memories': 494}\n",
            "495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-fbdddccf8583>:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n"
          ]
        }
      ],
      "source": [
        "# Read the dataset from csv - just first 10 songs for now\n",
        "dataset = pd.read_csv('/tmp/songdata.csv', dtype=str)[:10]\n",
        "# Create the corpus using the 'text' column containing lyrics\n",
        "corpus = create_lyrics_corpus(dataset, 'text')\n",
        "# Tokenize the corpus\n",
        "tokenizer = tokenize_corpus(corpus)\n",
        "\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(tokenizer.word_index)\n",
        "print(total_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9x68iN_X6FK"
      },
      "source": [
        "### Create Sequences and Labels\n",
        "\n",
        "After preprocessing, we next need to create sequences and labels. Creating the sequences themselves is similar to before with `texts_to_sequences`, but also including the use of [N-Grams](https://towardsdatascience.com/introduction-to-language-models-n-gram-e323081503d9); creating the labels will now utilize those sequences as well as utilize one-hot encoding over all potential output words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QmlTsUqfikVO"
      },
      "outputs": [],
      "source": [
        "sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tsequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences for equal input length \n",
        "max_sequence_len = max([len(seq) for seq in sequences])\n",
        "sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# Split sequences between the \"input\" sequence and \"output\" predicted word\n",
        "input_sequences, labels = sequences[:,:-1], sequences[:,-1]\n",
        "# One-hot encode the labels\n",
        "one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Zsmu3aEId49i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36144270-9967-4643-d6c9-b97f4ffef090"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32\n",
            "97\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0  81  82 142 197  29\n",
            "   4]\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0  81  82 142 197  29   4\n",
            " 287]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "# Check out how some of our data is being stored\n",
        "# The Tokenizer has just a single index per word\n",
        "print(tokenizer.word_index['know'])\n",
        "print(tokenizer.word_index['feeling'])\n",
        "# Input sequences will have multiple indexes\n",
        "print(input_sequences[5])\n",
        "print(input_sequences[6])\n",
        "# And the one hot labels will be as long as the full spread of tokenized words\n",
        "print(one_hot_labels[5])\n",
        "print(one_hot_labels[6])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1TAJMlmfO8r"
      },
      "source": [
        "### Train a Text Generation Model\n",
        "\n",
        "Building an RNN to train our text generation model will be very similar to the sentiment models you've built previously. The only real change necessary is to make sure to use Categorical instead of Binary Cross Entropy as the loss function - we could use Binary before since the sentiment was only 0 or 1, but now there are hundreds of categories.\n",
        "\n",
        "From there, we should also consider using *more* epochs than before, as text generation can take a little longer to converge than sentiment analysis, *and* we aren't working with all that much data yet. I'll set it at 200 epochs here since we're only use part of the dataset, and training will tail off quite a bit over that many epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "G1YXuxIqfygN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59015ceb-fd7c-4c01-dd0c-3ae922a0311c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "62/62 [==============================] - 17s 84ms/step - loss: 6.0021 - accuracy: 0.0217\n",
            "Epoch 2/200\n",
            "62/62 [==============================] - 3s 50ms/step - loss: 5.4394 - accuracy: 0.0363\n",
            "Epoch 3/200\n",
            "62/62 [==============================] - 1s 19ms/step - loss: 5.3633 - accuracy: 0.0444\n",
            "Epoch 4/200\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 5.3103 - accuracy: 0.0404\n",
            "Epoch 5/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 5.2394 - accuracy: 0.0484\n",
            "Epoch 6/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 5.1639 - accuracy: 0.0474\n",
            "Epoch 7/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 5.0918 - accuracy: 0.0550\n",
            "Epoch 8/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 5.0098 - accuracy: 0.0616\n",
            "Epoch 9/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 4.9182 - accuracy: 0.0691\n",
            "Epoch 10/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 4.8442 - accuracy: 0.0812\n",
            "Epoch 11/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.7467 - accuracy: 0.0848\n",
            "Epoch 12/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 4.6479 - accuracy: 0.0979\n",
            "Epoch 13/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 4.5490 - accuracy: 0.1075\n",
            "Epoch 14/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 4.4575 - accuracy: 0.1145\n",
            "Epoch 15/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.3721 - accuracy: 0.1317\n",
            "Epoch 16/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 4.2790 - accuracy: 0.1393\n",
            "Epoch 17/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 4.1823 - accuracy: 0.1524\n",
            "Epoch 18/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 4.0987 - accuracy: 0.1650\n",
            "Epoch 19/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 4.0132 - accuracy: 0.1791\n",
            "Epoch 20/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 3.9300 - accuracy: 0.1872\n",
            "Epoch 21/200\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 3.8391 - accuracy: 0.2028\n",
            "Epoch 22/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 3.7588 - accuracy: 0.2129\n",
            "Epoch 23/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 3.6856 - accuracy: 0.2296\n",
            "Epoch 24/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 3.6064 - accuracy: 0.2518\n",
            "Epoch 25/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.5261 - accuracy: 0.2719\n",
            "Epoch 26/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.4482 - accuracy: 0.2876\n",
            "Epoch 27/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.3765 - accuracy: 0.3093\n",
            "Epoch 28/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.3088 - accuracy: 0.3249\n",
            "Epoch 29/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.2674 - accuracy: 0.3330\n",
            "Epoch 30/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.1998 - accuracy: 0.3421\n",
            "Epoch 31/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 3.1262 - accuracy: 0.3582\n",
            "Epoch 32/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.0738 - accuracy: 0.3693\n",
            "Epoch 33/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 3.0194 - accuracy: 0.3819\n",
            "Epoch 34/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.9586 - accuracy: 0.3991\n",
            "Epoch 35/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.9083 - accuracy: 0.4057\n",
            "Epoch 36/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.8429 - accuracy: 0.4208\n",
            "Epoch 37/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.7661 - accuracy: 0.4349\n",
            "Epoch 38/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.7097 - accuracy: 0.4359\n",
            "Epoch 39/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 2.6556 - accuracy: 0.4531\n",
            "Epoch 40/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 2.6092 - accuracy: 0.4677\n",
            "Epoch 41/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 2.5521 - accuracy: 0.4768\n",
            "Epoch 42/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.4995 - accuracy: 0.4748\n",
            "Epoch 43/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.4704 - accuracy: 0.4879\n",
            "Epoch 44/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.4105 - accuracy: 0.5030\n",
            "Epoch 45/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.3627 - accuracy: 0.5116\n",
            "Epoch 46/200\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 2.3157 - accuracy: 0.5156\n",
            "Epoch 47/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 2.2712 - accuracy: 0.5242\n",
            "Epoch 48/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 2.2504 - accuracy: 0.5303\n",
            "Epoch 49/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 2.2151 - accuracy: 0.5424\n",
            "Epoch 50/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.1590 - accuracy: 0.5505\n",
            "Epoch 51/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.1276 - accuracy: 0.5600\n",
            "Epoch 52/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.0991 - accuracy: 0.5520\n",
            "Epoch 53/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.0805 - accuracy: 0.5641\n",
            "Epoch 54/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.0865 - accuracy: 0.5661\n",
            "Epoch 55/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 2.0299 - accuracy: 0.5686\n",
            "Epoch 56/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.9889 - accuracy: 0.5777\n",
            "Epoch 57/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.9568 - accuracy: 0.5853\n",
            "Epoch 58/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.9542 - accuracy: 0.5848\n",
            "Epoch 59/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.9027 - accuracy: 0.5933\n",
            "Epoch 60/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.8615 - accuracy: 0.6009\n",
            "Epoch 61/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.8260 - accuracy: 0.6080\n",
            "Epoch 62/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.7792 - accuracy: 0.6191\n",
            "Epoch 63/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.7505 - accuracy: 0.6231\n",
            "Epoch 64/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.7169 - accuracy: 0.6453\n",
            "Epoch 65/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.6869 - accuracy: 0.6448\n",
            "Epoch 66/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.6544 - accuracy: 0.6519\n",
            "Epoch 67/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.6342 - accuracy: 0.6625\n",
            "Epoch 68/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.6093 - accuracy: 0.6604\n",
            "Epoch 69/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.5816 - accuracy: 0.6751\n",
            "Epoch 70/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.5502 - accuracy: 0.6796\n",
            "Epoch 71/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.5335 - accuracy: 0.6862\n",
            "Epoch 72/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.5066 - accuracy: 0.6892\n",
            "Epoch 73/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.4894 - accuracy: 0.6998\n",
            "Epoch 74/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.4700 - accuracy: 0.7079\n",
            "Epoch 75/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.4363 - accuracy: 0.7084\n",
            "Epoch 76/200\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 1.4219 - accuracy: 0.7139\n",
            "Epoch 77/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.4106 - accuracy: 0.7205\n",
            "Epoch 78/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.3735 - accuracy: 0.7215\n",
            "Epoch 79/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.3632 - accuracy: 0.7270\n",
            "Epoch 80/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.3371 - accuracy: 0.7265\n",
            "Epoch 81/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.3139 - accuracy: 0.7417\n",
            "Epoch 82/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.2949 - accuracy: 0.7397\n",
            "Epoch 83/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.2780 - accuracy: 0.7417\n",
            "Epoch 84/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.2692 - accuracy: 0.7467\n",
            "Epoch 85/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.2705 - accuracy: 0.7407\n",
            "Epoch 86/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.2597 - accuracy: 0.7513\n",
            "Epoch 87/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.2277 - accuracy: 0.7553\n",
            "Epoch 88/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.1968 - accuracy: 0.7644\n",
            "Epoch 89/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.1704 - accuracy: 0.7659\n",
            "Epoch 90/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.1494 - accuracy: 0.7745\n",
            "Epoch 91/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.1328 - accuracy: 0.7800\n",
            "Epoch 92/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.1154 - accuracy: 0.7790\n",
            "Epoch 93/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.1045 - accuracy: 0.7810\n",
            "Epoch 94/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.1026 - accuracy: 0.7790\n",
            "Epoch 95/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.0857 - accuracy: 0.7780\n",
            "Epoch 96/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0671 - accuracy: 0.7856\n",
            "Epoch 97/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0518 - accuracy: 0.7846\n",
            "Epoch 98/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0418 - accuracy: 0.7830\n",
            "Epoch 99/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 1.0295 - accuracy: 0.7916\n",
            "Epoch 100/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.0041 - accuracy: 0.7921\n",
            "Epoch 101/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.0033 - accuracy: 0.7931\n",
            "Epoch 102/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.0117 - accuracy: 0.7841\n",
            "Epoch 103/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0115 - accuracy: 0.7861\n",
            "Epoch 104/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9851 - accuracy: 0.7936\n",
            "Epoch 105/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9670 - accuracy: 0.7972\n",
            "Epoch 106/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9521 - accuracy: 0.7962\n",
            "Epoch 107/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9244 - accuracy: 0.8068\n",
            "Epoch 108/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.9099 - accuracy: 0.8088\n",
            "Epoch 109/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9592 - accuracy: 0.7936\n",
            "Epoch 110/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9233 - accuracy: 0.8012\n",
            "Epoch 111/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8823 - accuracy: 0.8133\n",
            "Epoch 112/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8692 - accuracy: 0.8103\n",
            "Epoch 113/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8540 - accuracy: 0.8113\n",
            "Epoch 114/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8512 - accuracy: 0.8133\n",
            "Epoch 115/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8342 - accuracy: 0.8179\n",
            "Epoch 116/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8222 - accuracy: 0.8209\n",
            "Epoch 117/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8159 - accuracy: 0.8209\n",
            "Epoch 118/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8040 - accuracy: 0.8259\n",
            "Epoch 119/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7969 - accuracy: 0.8189\n",
            "Epoch 120/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7966 - accuracy: 0.8254\n",
            "Epoch 121/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7882 - accuracy: 0.8259\n",
            "Epoch 122/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7691 - accuracy: 0.8340\n",
            "Epoch 123/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7609 - accuracy: 0.8269\n",
            "Epoch 124/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.7592 - accuracy: 0.8290\n",
            "Epoch 125/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.7550 - accuracy: 0.8335\n",
            "Epoch 126/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9030 - accuracy: 0.7881\n",
            "Epoch 127/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.8604 - accuracy: 0.8027\n",
            "Epoch 128/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.7947 - accuracy: 0.8169\n",
            "Epoch 129/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.7526 - accuracy: 0.8249\n",
            "Epoch 130/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.7298 - accuracy: 0.8320\n",
            "Epoch 131/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7136 - accuracy: 0.8315\n",
            "Epoch 132/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6973 - accuracy: 0.8380\n",
            "Epoch 133/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6907 - accuracy: 0.8416\n",
            "Epoch 134/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6797 - accuracy: 0.8512\n",
            "Epoch 135/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6733 - accuracy: 0.8446\n",
            "Epoch 136/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6667 - accuracy: 0.8491\n",
            "Epoch 137/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6584 - accuracy: 0.8502\n",
            "Epoch 138/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6461 - accuracy: 0.8537\n",
            "Epoch 139/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6379 - accuracy: 0.8532\n",
            "Epoch 140/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6341 - accuracy: 0.8517\n",
            "Epoch 141/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6268 - accuracy: 0.8567\n",
            "Epoch 142/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6190 - accuracy: 0.8557\n",
            "Epoch 143/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6145 - accuracy: 0.8562\n",
            "Epoch 144/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6066 - accuracy: 0.8607\n",
            "Epoch 145/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6004 - accuracy: 0.8618\n",
            "Epoch 146/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5982 - accuracy: 0.8597\n",
            "Epoch 147/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6286 - accuracy: 0.8512\n",
            "Epoch 148/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6102 - accuracy: 0.8592\n",
            "Epoch 149/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5963 - accuracy: 0.8542\n",
            "Epoch 150/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5829 - accuracy: 0.8597\n",
            "Epoch 151/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5720 - accuracy: 0.8633\n",
            "Epoch 152/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5683 - accuracy: 0.8663\n",
            "Epoch 153/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5690 - accuracy: 0.8623\n",
            "Epoch 154/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.5684 - accuracy: 0.8597\n",
            "Epoch 155/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.5543 - accuracy: 0.8648\n",
            "Epoch 156/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.5458 - accuracy: 0.8683\n",
            "Epoch 157/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.5358 - accuracy: 0.8688\n",
            "Epoch 158/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.5314 - accuracy: 0.8698\n",
            "Epoch 159/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5316 - accuracy: 0.8683\n",
            "Epoch 160/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5291 - accuracy: 0.8673\n",
            "Epoch 161/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5256 - accuracy: 0.8678\n",
            "Epoch 162/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5238 - accuracy: 0.8693\n",
            "Epoch 163/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5460 - accuracy: 0.8678\n",
            "Epoch 164/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5299 - accuracy: 0.8693\n",
            "Epoch 165/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5117 - accuracy: 0.8749\n",
            "Epoch 166/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5048 - accuracy: 0.8759\n",
            "Epoch 167/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4954 - accuracy: 0.8779\n",
            "Epoch 168/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4949 - accuracy: 0.8764\n",
            "Epoch 169/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4905 - accuracy: 0.8769\n",
            "Epoch 170/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4967 - accuracy: 0.8749\n",
            "Epoch 171/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5006 - accuracy: 0.8764\n",
            "Epoch 172/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4856 - accuracy: 0.8749\n",
            "Epoch 173/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4790 - accuracy: 0.8774\n",
            "Epoch 174/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4756 - accuracy: 0.8789\n",
            "Epoch 175/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4681 - accuracy: 0.8819\n",
            "Epoch 176/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4792 - accuracy: 0.8794\n",
            "Epoch 177/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4692 - accuracy: 0.8779\n",
            "Epoch 178/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4576 - accuracy: 0.8819\n",
            "Epoch 179/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4524 - accuracy: 0.8840\n",
            "Epoch 180/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4590 - accuracy: 0.8819\n",
            "Epoch 181/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4710 - accuracy: 0.8804\n",
            "Epoch 182/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.4626 - accuracy: 0.8799\n",
            "Epoch 183/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.4464 - accuracy: 0.8870\n",
            "Epoch 184/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.4405 - accuracy: 0.8875\n",
            "Epoch 185/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.4375 - accuracy: 0.8845\n",
            "Epoch 186/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.4357 - accuracy: 0.8890\n",
            "Epoch 187/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4339 - accuracy: 0.8860\n",
            "Epoch 188/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4267 - accuracy: 0.8905\n",
            "Epoch 189/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4292 - accuracy: 0.8890\n",
            "Epoch 190/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4239 - accuracy: 0.8920\n",
            "Epoch 191/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4197 - accuracy: 0.8915\n",
            "Epoch 192/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4214 - accuracy: 0.8946\n",
            "Epoch 193/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4133 - accuracy: 0.8920\n",
            "Epoch 194/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4216 - accuracy: 0.8900\n",
            "Epoch 195/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4141 - accuracy: 0.8925\n",
            "Epoch 196/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4042 - accuracy: 0.8930\n",
            "Epoch 197/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4010 - accuracy: 0.8946\n",
            "Epoch 198/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3966 - accuracy: 0.8961\n",
            "Epoch 199/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3923 - accuracy: 0.8971\n",
            "Epoch 200/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.3941 - accuracy: 0.8920\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(20)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(input_sequences, one_hot_labels, epochs=200, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXVFpoREhV6Y"
      },
      "source": [
        "### View the Training Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aeSNfS7uhch0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "17cae040-c93c-44e1-bba3-4cbb9e11b23c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()\n",
        "\n",
        "plot_graphs(history, 'accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rAgRpxYhjpB"
      },
      "source": [
        "### Generate new lyrics!\n",
        "\n",
        "It's finally time to generate some new lyrics from the trained model, and see what we get. To do so, we'll provide some \"seed text\", or an input sequence for the model to start with. We'll also decide just how long of an output sequence we want - this could essentially be infinite, as the input plus the previous output will be continuously fed in for a new output word (at least up to our max sequence length)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "DC7zfcgviDTp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebbcb817-628e-43d0-c979-db1aaf4cdac5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 628ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "im feeling chills you to be so even butterflies friend every never never song night velvet dimension song darkest dimension life return found found chiquitita give cause youre making me strong life cryin you smart start start start final pain start pain pain will scars kind show song chiquitita saw lucky on found growing found growing smiled break break life return found found thorough dumb chiquitita talking sucker walk growing cause please i return to rotten show be see never hope never beg song final pavement final night night bedumbedumdum final like growing start walls sky chiquitita return found found cause youre making\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}